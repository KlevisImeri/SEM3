1. It's so hard to describe what exactly dynamic programming is, because it's more of an idea that works in a lot of situations than a concrete framework. Also people call a lot of things dynamic programming, that are not really dynamic programming. I think I have also been teaching dynamic programming a lot with Fibonacci numbers but at this point in time I actually think that's not the best example... I would even say it completely misses the point, because it does not capture what dynamic programming **is**, it instead only captures how to **implement** dynamic programming efficiently, which is also very interesting, but a very different idea.
    What dynamic programming is boils down to one idea, that they usually call the "principle of optimality". I think a lot about what is a good example that can be used to introduce dynamic programming to people new to it, right now my favourite one is this: You have N plastic cards with positive numbers written on them laid out in a row in front of you. Find the subset of plastic cards that have the maximum sum of numbers on them where none of them are neighbours in the layout. If you imagine a naive solution to this, you could try all 2^N subsets of the cards, check that your current selection does not have neighbours in it, compute their sum and keep track of the maximum you have seen. It is a correct solution, but very exponential.
    If I think about what kinds of solutions I would get from students on an exam, a few examples: Take the sum of every odd card and also every even card. The one having the bigger sum is the solution. Won't work, cause it might be worth it to skip more than one card to pick out really big ones. A small example is "1000, 1, 1, 1000". Best solution is 2000, the algorithm described above will return 1001. Upon learning this many students will come up with a better heuristic. :) Okay so how about we start at the beginning and look at the first, 4 cards and pick the one with the largest number, then always look ahead again, the next 4 cards (except the one that is right next to the already picked) and pick the largest, until you reach the end and that's the best solution. Well I can kinda see a problem there, being what if you deny yourself a very big card, because you picked something that was a neighbour of it. E.g. 1,1,1,10,10^8. :) And they can keep coming up with better heuristics and I can keep coming up with even better counterexamples until the end of time. The main problem with heuristic solutions like this is that they usually make a decision that makes them skip a possible solution from the 2^N solutions that could have been better than any of the other ones. They skip it without having any information on it. However we still must be able to skip checking some of the 2^N possible solutions if we want to make our algorithm better than exponential, but we cannot do so without having any information that that specific selection would not be optimal anyways.
    This is where the principle of optimality comes in: if a problem admits to it it means that an optimal solution to it comes from optimal solutions to a few smaller subproblems. I very much dislike this explanation by the way, but I have not found a better one yet. I don't like the word "subproblems" in particular, because it can mean anything, so it just means nothing to someone just learning this. But anyhow I usually solve problems like this is I look at one of the entities, usually thse last one (in this case the Nth card), and say "this is either part of the optimal solution or it is not". -> If it is part of the optimal solution then the optimal solution to the subproblem with cards 1..N-2 + the value of the Nth card is the optimal solution. Since the N-1th card cannot be part of the solution if the Nth is present. -> If it is not part of the optimal solution, then the optimal solution is the same as the optimal solution to the subproblem with cards 1..N-1. So this is kind of like a **decision point** actually, it can sometimes be more than 1, for example you remember the Tribonacchi tiling problem where we picked which type of tile is the last one.
    And the way I like to visualise it is by saying: imagine someone gave you the task to write down all 2^N possible solutions to this problem, you have a very long list of 0's and 1's for example, or something easier to see would be _ and X, where X marks the selected cards and _ marks an empty space / not selected card. You would imagine this list like this: ________ _______X ______X_ ... XXXXXXXX Then imagine somewhere along the list you had to mark with a pen the optimal solution, e.g.: ________ _______X ______X_ ... _X_X__X_ <- That one. ... X_X_X_X_ Now the decision point we made above focuses on the very last column, let's highlight that. Group all of these possible solutions into two, the ones that have X in them and the ones that don't at the last position: The first group: ________ ______X_ ... X_X_X_X_ And the other group: _______X _____X_X ... X_X_X__X If we look at the first group closely and we remove the last column, which contains _ always: ________ ______X_ ... X_X_X_X_ These will contain all possible solutions to the 1..N-1 subproblem. If our optimal solution is hiding in this list, then it will be at the exact same position the optimal solution to this whole subproblem is: _______ ______X ... X_X_X_X If we look at the second group closely and we remove the last two columns, which all contain _X by the way: _______X _____X_X ... X_X_X__X If our optimal solution is here, then after removing the columns we have the optimal solution to the 1...N-2 subproblem highlighted and the list is the same as the list for the 1...N-2 subproblem. ______ _____X ... X_X_X_ (edited)
    
    I think this visualisation still needs some more thinking / work on how to explain it best, if you look at this (sadly hungarian :( ) video I made, at this time stamp: [https://youtu.be/1BXs3aZPPsw?t=4841](https://youtu.be/1BXs3aZPPsw?t=4841 "https://youtu.be/1BXs3aZPPsw?t=4841") I'm doing something similar, to the problem of the ladder where you can step 1,2 or 3 steps at one time. I listed them how a solution might look like (a list of numbers 1,2,3 ...) and highlighted the last number, organized the lists without that number into 3 groups. How to generalize this thinking is so hard to figure out. I was thinking of saying it is used in selection problems of N entities with some constraints and an optimized property, but I'm not sure it only applies to selection problems. Assignment problems might also work and optimal ordering even maybe. Also bitset DP is a solution to the hamiltonian cycle problem, which makes it go from N! to 2^N * N^2 or something similar. That is a more advanced version of the same idea. And then the way we **implement** this efficiently is by memoizing the optimal solutions to subproblems and then instead of recursion we use a loop. You do this when calculating Fibonacchi numbers, but Fibonacchi numbers have nothing to do with the principle of optimality I think. So these are two different ideas actually.